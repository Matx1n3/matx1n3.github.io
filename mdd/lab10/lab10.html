<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Laboratorio 10</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    .output {
    	background-color: #f2eeda;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: #d1d0cb;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  
</head>
<body>
<section id="ejericio-2-clasificando-gatos-con-regresión-logística"
class="cell markdown" id="KtPe9mrrueNX">
<h1>Laboratorio 10: Clasificando Gatos con Regresión Logística</h1>
<p>En el ejercicio anterior cargamos los datos de unos ficheros con
imágenes de gatos. En este segundo ejercicio, aprenderemos un modelo muy
simple de regresión logística. Recuerda que ese modelo se puede
considerar una versión muy simple de una red neuronal. A continuación,
el diagrama que describe el modelo que vamos a implementar:</p>
<p><img
src="https://drive.google.com/uc?id=1VfKgnsvczXqKMMMGz_GR8reLQUIX7kDS"
alt="alt text" /></p>
</section>
<div class="cell markdown" id="ns4yH3kdwEud">
<p>La expresión matemática del algoritmo</p>
<p>Para una muestra de datos <span
class="math inline"><em>x</em><sup>(<em>i</em>)</sup></span>:</p>
<p><span
class="math inline"><em>z</em><sup>(<em>i</em>)</sup> = <em>W</em><sup><em>T</em></sup><em>x</em><sup>(<em>i</em>)</sup> + <em>b</em></span></p>
<p><span
class="math inline"><em>ŷ</em> = <em>a</em><sup>(<em>i</em>)</sup> = <em>σ</em>(<em>z</em><sup>(<em>i</em>)</sup>)</span></p>
<p><span
class="math inline">(<em>a</em><sup>(<em>i</em>)</sup>,<em>y</em><sup>(<em>i</em>)</sup>) =  − <em>y</em><sup>(<em>i</em>)</sup><em>l</em><em>o</em><em>g</em>(<em>a</em><sup>(<em>i</em>)</sup> − (1−<em>y</em><sup>(<em>i</em>)</sup>)<em>l</em><em>o</em><em>g</em>(1−<em>a</em><sup>(<em>i</em>)</sup>)</span></p>
<p>La función de coste se consigue calculando sobre todas las muestras
de train:</p>
<p><span class="math inline">$J = \frac{1}{m} \Sigma_{i=1}^m (a^{(i)},
y^{(i)})$</span></p>
<p>Estas son las tareas principales a realizar en este ejercicio:</p>
<ul>
<li>Inicializar los parámetros del modelo.</li>
<li>Aprender los parámetros óptimos del modelo minimizando la función de
coste.</li>
<li>Clasificar las muestras de test con los parámetros aprendidos.</li>
<li>Analizar los resultados y extraer conclusiones.</li>
</ul>
</div>
<section id="preparación-del-entorno" class="cell markdown"
id="pT8EenemyyL3">
<h1>Preparación del entorno</h1>
<p>Para comenzar el ejercicio, tenemos que importar las librerías,
cargar los datasets y estandarizar los datos. Ya hicimos eso en el
ejercicio anterior, así que nos limitaremos a pegar el código y a
ejecutarlo.</p>
</section>
<div class="cell code" data-execution_count="1" id="e1ubuKrNh70u">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> h5py</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> ndimage</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="2"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="Lq8ikAFNMirl" data-outputId="ca36b4cb-86ac-4c95-d06d-6534c737adaa">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget <span class="op">-</span>O train_catvnoncat.h5 https:<span class="op">//</span>ehubox.ehu.eus<span class="op">/</span>s<span class="op">/</span><span class="dv">62</span><span class="er">gBFyzGpDD7rei</span><span class="op">/</span>download</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>wget <span class="op">-</span>O test_catvnoncat.h5 https:<span class="op">//</span>ehubox.ehu.eus<span class="op">/</span>s<span class="op">/</span>eBa6kaBjyK3nwSf<span class="op">/</span>download</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>ls</span></code></pre></div>
<div class="output stream stdout">
<pre><code>--2023-12-30 18:28:38--  https://ehubox.ehu.eus/s/62gBFyzGpDD7rei/download
Resolving ehubox.ehu.eus (ehubox.ehu.eus)... 158.227.0.95
Connecting to ehubox.ehu.eus (ehubox.ehu.eus)|158.227.0.95|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 2572022 (2.5M) [application/octet-stream]
Saving to: ‘train_catvnoncat.h5’

train_catvnoncat.h5 100%[===================&gt;]   2.45M  1.13MB/s    in 2.2s    

2023-12-30 18:28:41 (1.13 MB/s) - ‘train_catvnoncat.h5’ saved [2572022/2572022]

--2023-12-30 18:28:41--  https://ehubox.ehu.eus/s/eBa6kaBjyK3nwSf/download
Resolving ehubox.ehu.eus (ehubox.ehu.eus)... 158.227.0.95
Connecting to ehubox.ehu.eus (ehubox.ehu.eus)|158.227.0.95|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 616958 (602K) [application/octet-stream]
Saving to: ‘test_catvnoncat.h5’

test_catvnoncat.h5  100%[===================&gt;] 602.50K   499KB/s    in 1.2s    

2023-12-30 18:28:43 (499 KB/s) - ‘test_catvnoncat.h5’ saved [616958/616958]

sample_data  test_catvnoncat.h5  train_catvnoncat.h5
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="3" id="gN2Dd5Niltn7">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_dataset():</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  train_dataset <span class="op">=</span> h5py.File(<span class="st">&quot;train_catvnoncat.h5&quot;</span>, <span class="st">&quot;r&quot;</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  train_set_x_orig <span class="op">=</span> np.array(train_dataset[<span class="st">&quot;train_set_x&quot;</span>][:]) <span class="co"># your train set features</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  train_set_y_orig <span class="op">=</span> np.array(train_dataset[<span class="st">&quot;train_set_y&quot;</span>][:]) <span class="co"># your train set labels</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  test_dataset <span class="op">=</span> h5py.File(<span class="st">&quot;test_catvnoncat.h5&quot;</span>, <span class="st">&quot;r&quot;</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  test_set_x_orig <span class="op">=</span> np.array(test_dataset[<span class="st">&quot;test_set_x&quot;</span>][:]) <span class="co"># your test set features</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  test_set_y_orig <span class="op">=</span> np.array(test_dataset[<span class="st">&quot;test_set_y&quot;</span>][:]) <span class="co"># your test set labels</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  classes <span class="op">=</span> np.array(test_dataset[<span class="st">&quot;list_classes&quot;</span>][:]) <span class="co"># the list of classes</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  train_set_y_orig <span class="op">=</span> train_set_y_orig.reshape((<span class="dv">1</span>, train_set_y_orig.shape[<span class="dv">0</span>]))</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  test_set_y_orig <span class="op">=</span> test_set_y_orig.reshape((<span class="dv">1</span>, test_set_y_orig.shape[<span class="dv">0</span>]))</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="4"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:449}"
id="kmPaVkuPm3MQ" data-outputId="74313700-7efb-4df9-bb35-1a79e7b7b8e8">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loading the data (cat/non-cat)</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes <span class="op">=</span> load_dataset()</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Example of a picture</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(train_set_x_orig[index])</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;y = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y[:, index]) <span class="op">+</span> <span class="st">&quot;, it&#39;s a &#39;&quot;</span> <span class="op">+</span> classes[np.squeeze(train_set_y[:, index])].decode(<span class="st">&quot;utf-8&quot;</span>) <span class="op">+</span>  <span class="st">&quot;&#39; picture.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>y = [0], it&#39;s a &#39;non-cat&#39; picture.
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_80e758b3b43443038c279ae53cfe7ffc/ec25fe5ead8e919a2ec91fa79a02b298765dfb06.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="5"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="SD4r8GmrqzPh" data-outputId="afde0203-5728-4c63-d8e1-b31348d746a6">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>m_train <span class="op">=</span> train_set_x_orig.shape[<span class="dv">0</span>]</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>m_test <span class="op">=</span> test_set_x_orig.shape[<span class="dv">0</span>]</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>num_px_height <span class="op">=</span> train_set_x_orig.shape[<span class="dv">1</span>]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>num_px_width <span class="op">=</span> train_set_x_orig.shape[<span class="dv">2</span>]</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>num_px <span class="op">=</span> num_px_width</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Cantidad de muestras de train: m_train = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(m_train))</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Cantidad de muestras de test:  m_test = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(m_test))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Altura de las imágenes: num_px_height = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(num_px_height))</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Anchura de las imágenes: num_px_width = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(num_px_width))</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Tamaño de cada imagen: (&quot;</span> <span class="op">+</span> <span class="bu">str</span>(num_px_height) <span class="op">+</span> <span class="st">&quot;, &quot;</span> <span class="op">+</span> <span class="bu">str</span>(num_px_width) <span class="op">+</span> <span class="st">&quot;, 3)&quot;</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Estructura de las muestras de train X: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_x_orig.shape))</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Estructura de las etiquetas de train Y: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y.shape))</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Estructura de las muestras de test X: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_x_orig.shape))</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Estructura de las etiquetas de test Y: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_y.shape))</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Vamos a reestructurar los datos, convirtiendo el cubo que forma una imagen [height, width, channels] a un vector de height*width*channel elementos</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>train_set_x_flatten <span class="op">=</span> train_set_x_orig.reshape(train_set_x_orig.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>).T</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>test_set_x_flatten <span class="op">=</span> test_set_x_orig.reshape(test_set_x_orig.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>).T</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;X_train.shape: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_x_flatten.shape))</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;X train.ndim; &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_x_flatten.ndim))</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Y_train.shape: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_y.shape))</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;X_test.shape: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_x_flatten.shape))</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Y_test.shape: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_y.shape))</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;Verifica que los datos se han reestructurado correctamente: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(train_set_x_flatten[<span class="dv">0</span>:<span class="dv">5</span>, <span class="dv">0</span>]))</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Para estandarizar los datos, dividiremos el valor de cada pixel por el valor maximo (255 en este caso).</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>train_set_x <span class="op">=</span> train_set_x_flatten<span class="op">/</span><span class="fl">255.</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>test_set_x <span class="op">=</span> test_set_x_flatten<span class="op">/</span><span class="fl">255.</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Cantidad de muestras de train: m_train = 209
Cantidad de muestras de test:  m_test = 50
Altura de las imágenes: num_px_height = 64
Anchura de las imágenes: num_px_width = 64
Tamaño de cada imagen: (64, 64, 3)
Estructura de las muestras de train X: (209, 64, 64, 3)
Estructura de las etiquetas de train Y: (1, 209)
Estructura de las muestras de test X: (50, 64, 64, 3)
Estructura de las etiquetas de test Y: (1, 50)
X_train.shape: (12288, 209)
X train.ndim; 2
Y_train.shape: (1, 209)
X_test.shape: (12288, 50)
Y_test.shape: (1, 50)
Verifica que los datos se han reestructurado correctamente: [17 31 56 22 33]
</code></pre>
</div>
</div>
<section id="construyendo-el-algoritmo" class="cell markdown"
id="bXDfRERRz5jC">
<h1>Construyendo el algoritmo</h1>
<p>Para entrenar una red neuronal, tenemos que implementar las
siguientes líneas:</p>
<ol>
<li>Definir la estructura del modelo (¿cuántas varaibles de
entrada?).</li>
<li>Inicializar los parámetros del modelo.</li>
<li>Loop:</li>
</ol>
<ul>
<li>Calcular el valor de la función de coste (forward pass).</li>
<li>Calcular el valor de los gradientes (backward pass).</li>
<li>Actualizar los parámetros (gradient descent).</li>
</ul>
<p>A continuación, vamos a implementar cada parte de forma separada para
juntar todas al final, implementando una red neuronal.</p>
</section>
<section id="21-funciones-ayudantes" class="cell markdown"
id="1ECoCRW01HYl">
<h2>2.1 Funciones ayudantes</h2>
<p>Implementa la función sigmoid() (<span
class="math inline"><em>σ</em></span>). Más adelante la necesitaremos,
para calcular las predicciones <span
class="math inline"><em>σ</em>(<em>W</em><sup><em>T</em></sup><em>x</em>+<em>b</em>)</span>.
Recuerda que <span class="math inline">$\sigma(z) =
\frac{1}{1+e^{-z}}$</span></p>
</section>
<div class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="C68NkJ2w1wsM" data-outputId="86053149-68c8-406f-e64f-1aa7a66ef534">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sigmoid funtzioa</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(z):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula el sigmoide de z</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Input:</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">    z -- Un número real o un numpy-array de números reales.</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Output:</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co">    s -- sigmoid(z)</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span><span class="op">+</span>np.exp(<span class="op">-</span>z))</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;sigmoid([0, 2]) = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(sigmoid(np.array([<span class="dv">0</span>,<span class="dv">2</span>]))))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>sigmoid([0, 2]) = [0.5        0.88079708]
</code></pre>
</div>
</div>
<section id="22-inicializar-los-parámetros" class="cell markdown"
id="gtWIo50l3Nl3">
<h2>2.2 Inicializar los parámetros</h2>
<p><strong>Ejercicio:</strong> Tienes que inicializar los parámetros en
el siguiente código. Para eso, crea el array <span
class="math inline"><em>w</em></span> con ceros. <strong>Pista:</strong>
mira la función np.zeros().</p>
</section>
<div class="cell code" data-execution_count="7"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="MY7lF8Ta3s4z" data-outputId="4346a7ce-d72b-4a51-cec4-8a264e66812f">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_with_zeros(dim):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Esta funcion crea un vector de ceros de dimensiones (dim, 1), para inicializar w y b.</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Argument:</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co">    dim -- tamaño del vector w.</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co">    w -- vector w de ceros con dimension (dim, 1).</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">    b -- parametro b inicializado a 0.</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> np.zeros((dim, <span class="dv">1</span>))</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(w.shape <span class="op">==</span> (dim, <span class="dv">1</span>))</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(<span class="bu">isinstance</span>(b, <span class="bu">float</span>) <span class="kw">or</span> <span class="bu">isinstance</span>(b, <span class="bu">int</span>))</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> w, b</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>dim <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>w, b <span class="op">=</span> initialize_with_zeros(dim)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;w = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(w))</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;b = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(b))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>w = [[0.]
 [0.]]
b = 0
</code></pre>
</div>
</div>
<div class="cell markdown" id="MAzZpyg4PzSF">
<p>Gure datuak irudiak direnean, <span
class="math inline"><em>w</em></span> (num_px × num_px × 3, 1)
dimentsioko bektorea izango da.</p>
</div>
<section id="23-forward-y-backward-pass" class="cell markdown"
id="YYLu1VhjP8sd">
<h1>2.3 Forward y backward pass</h1>
<p>Una vez inicializados los parámetros del modelo, dado un dataset de
train, tenemos que implementar las funciones forward y backward que nos
permitan aprender los parámetros.</p>
<p><strong>Ejercicio:</strong> Implementa la función de coste y su
gradiente en la función propagate().</p>
<p><strong>Pistas:</strong></p>
<p>Forward pass:</p>
<ul>
<li>Consigue <span class="math inline"><em>X</em></span>.</li>
<li>Calcula $A = \sigma (W^T X + b) = (a^{(1)}, a^{(2)}, \ldots,
a^{(m)}) $</li>
<li>Calcula la función de coste <span class="math inline">$J =
-\frac{1}{m}\Sigma_{i=1}^m y^{(i)} log(a^(i)) + (1-y^{(i)})
log(1-a^{(i)})$</span></li>
</ul>
<p>Backward pass:</p>
<ul>
<li><span class="math inline">$\frac{\delta J}{\delta w} = \frac{1}{m} X
(A-Y)^T$</span></li>
<li><span class="math inline">$\frac{\delta J}{\delta b} = \frac{1}{m}
\Sigma_{i=1}^m (a^{(i)}-y^{(i)})$</span></li>
</ul>
</section>
<div class="cell code" data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="uXHxaEX_Rm5f" data-outputId="c15ae6f2-1c3e-4017-a9e7-2ac252f1eef5">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> propagate(w, b, X, Y):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calcula la funcion de coste y su gradiente ejecutando el forward y el backward pass.</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Input:</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">    w -- pesos, numpy-array de tamaño (num_px * num_px * 3, 1).</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">    b -- parametro b (bias).</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">    X -- Conjunto de muestras X de train. Dimension: (num_px * num_px * 3, number of examples)</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Y -- Conjunto de etiquetas Y de train (0 -&gt; no gato, 1 -&gt; gato). Dimension: (1, number of examples)</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Output:</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">    cost -- Coste de la regresion logistica.</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co">    dw -- gradiente de la funcion de coste respecto a w.</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co">    db -- gradiente de la funcion de coste respecto a b.</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Pista:</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="co">    - Escribe tu codigo paso a paso para la propagacion. np.log(), np.dot()</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># FORWARD PASS (empezando desde X hasta calcular el coste)</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">## PON TU CODIGO AQUI ##  (≈ 2 lineas de codigo)</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> sigmoid(np.dot(w.T, X) <span class="op">+</span> b)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> <span class="op">-</span><span class="dv">1</span><span class="op">/</span>m <span class="op">*</span> np.<span class="bu">sum</span>(Y <span class="op">*</span> np.log(A) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> Y) <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">-</span> A))</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">######################</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># BACKWARD PASS (calcula el gradiente)</span></span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="co">## PON TU CODIGO AQUI ## (≈ 3 lineas de codigo)</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    dw <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>m <span class="op">*</span> np.dot(X, (A <span class="op">-</span> Y).T)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    db <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>m <span class="op">*</span> np.<span class="bu">sum</span>(A <span class="op">-</span> Y)</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">######################</span></span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(dw.shape <span class="op">==</span> w.shape)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(db.dtype <span class="op">==</span> <span class="bu">float</span>)</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.squeeze(cost)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(cost.shape <span class="op">==</span> ())</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    grads <span class="op">=</span> {<span class="st">&quot;dw&quot;</span>: dw,</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>             <span class="st">&quot;db&quot;</span>: db}</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> grads, cost</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>w, b, X, Y <span class="op">=</span> np.array([[<span class="fl">1.</span>],[<span class="fl">2.</span>]]), <span class="fl">2.</span>, np.array([[<span class="fl">1.</span>,<span class="fl">2.</span>,<span class="op">-</span><span class="fl">1.</span>],[<span class="fl">3.</span>,<span class="fl">4.</span>,<span class="op">-</span><span class="fl">3.2</span>]]), np.array([[<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>]])</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>grads, cost <span class="op">=</span> propagate(w, b, X, Y)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;dw = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(grads[<span class="st">&quot;dw&quot;</span>]))</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;db = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(grads[<span class="st">&quot;db&quot;</span>]))</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;cost = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(cost))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>dw = [[0.99845601]
 [2.39507239]]
db = 0.001455578136784208
cost = 5.801545319394553
</code></pre>
</div>
</div>
<section id="24-gradient-descent" class="cell markdown"
id="iU_bogRAt-XN">
<h2>2.4 Gradient descent</h2>
<p>En este punto ya:</p>
<ul>
<li>has inicializado los parámetros,</li>
<li>eres capaz de calcular la función de coste y el gradiente,</li>
<li>vas a actualizar los parámetros usando el algoritmo "gradient
descent" (descenso de gradiente)</li>
</ul>
<p><strong>Ejercicio:</strong> implementa el algoritmo de descenso de
gradiente en la función optimize(). Recuerda que el objetivo es aprender
los parámetros <span class="math inline"><em>w</em></span> y <span
class="math inline"><em>b</em></span> que minimicen la función <span
class="math inline"><em>J</em></span>. Para cualquier parámetro <span
class="math inline"><em>θ</em></span>, éste se actualiza segun la regla
<span
class="math inline"><em>θ</em> = <em>θ</em> − <em>α</em><em>δ</em><em>θ</em></span>,
donde <span class="math inline"><em>α</em></span> es la tasa de
aprendizaje (learning rate).</p>
</section>
<div class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="LoZvqDA0vvyt" data-outputId="b27f4fd4-d4cf-4555-93be-212995383c09">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> optimize(w, b, X, Y, num_iterations, learning_rate, print_cost <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Esta función optimiza los parámetros w y b para minimizar la función de coste siguiendo</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">    el algoritmo de gradient descent.</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Input:</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">    w -- pesos, numpy-array de tamaño (num_px * num_px * 3, 1).</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">    b -- parámetro b (bias).</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">    X -- Conjunto de muestras X de train. Dimension: (num_px * num_px * 3, number of examples)</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Y -- Conjunto de etiquetas Y de train (0 -&gt; no gato, 1 -&gt; gato). Dimension: (1, number of examples)</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">    num_iterations -- numero de iteraciones del algoritmo.</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co">    learning_rate -- tasa de aprendizaje de la regla de actualización.</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co">    print_cost -- cuando es True, imprime el valor del gradiente cada 100 iteraciones.</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co">    Output:</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co">    params -- diccionario que guarda los parametros w y b.</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co">    grads -- diccionario que guarda los gradientes de los parametros w y b respecto a la funcion de coste.</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co">    costs -- lista donde se guardan los valores de coste. Los usaremos para generar una grafica.</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Pistas:</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="co">    Tienes que implementar dos pasos e iterar sobre ellos:</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="co">        1) Calcular el coste y el gradiente para los parametros actuales. Usa propagate()</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="co">        2) Actualizar los parametros w y b utilizando la regla de actualizacion del descenso de gradiente .</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    costs <span class="op">=</span> []</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {<span class="st">&#39;w&#39;</span>:w,</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>             <span class="st">&#39;b&#39;</span>:b}</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_iterations):</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculo del coste y del gradiente (≈ 1 linea de codigo)</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>        grads, cost <span class="op">=</span> propagate(w, b, X, Y)</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>        <span class="co">######################</span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Retrieve derivatives from grads</span></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>        dw <span class="op">=</span> grads[<span class="st">&quot;dw&quot;</span>]</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>        db <span class="op">=</span> grads[<span class="st">&quot;db&quot;</span>]</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">## PON TU CODIGO AQUI ## #regla de actualizacion (≈ 3 lineas de codigo)</span></span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>        w <span class="op">=</span> w <span class="op">-</span> learning_rate <span class="op">*</span> dw</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>        b <span class="op">=</span> b <span class="op">-</span> learning_rate <span class="op">*</span> db</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>        <span class="co">######################</span></span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Guarda los costes.</span></span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>            costs.append(cost)</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Imprime el coste cada 100 iteraciones.</span></span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> print_cost <span class="kw">and</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span> (<span class="st">&quot;Cost after iteration </span><span class="sc">%i</span><span class="st">: </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span>(i, cost))</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {<span class="st">&quot;w&quot;</span>: w,</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>              <span class="st">&quot;b&quot;</span>: b}</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>    grads <span class="op">=</span> {<span class="st">&quot;dw&quot;</span>: dw,</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>             <span class="st">&quot;db&quot;</span>: db}</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> params, grads, costs</span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a>params, grads, costs <span class="op">=</span> optimize(w, b, X, Y, num_iterations<span class="op">=</span> <span class="dv">100</span>, learning_rate <span class="op">=</span> <span class="fl">0.009</span>, print_cost <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;w = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(params[<span class="st">&quot;w&quot;</span>]))</span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;b = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(params[<span class="st">&quot;b&quot;</span>]))</span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;dw = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(grads[<span class="st">&quot;dw&quot;</span>]))</span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;db = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(grads[<span class="st">&quot;db&quot;</span>]))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>w = [[0.19033591]
 [0.12259159]]
b = 1.9253598300845747
dw = [[0.67752042]
 [1.41625495]]
db = 0.21919450454067657
</code></pre>
</div>
</div>
<div class="cell markdown" id="Nd2-uUlJzcgc">
<p><strong>Ejercicio:</strong> La función anterior calcula los
parámetros <span class="math inline"><em>w</em></span> y <span
class="math inline"><em>b</em></span>. La última función que necesitamos
es la función predict(). Esta función será capaz de predecir la clase de
unas muestras de test <span class="math inline"><em>X</em></span>, dados
los parámetros <span class="math inline"><em>w</em></span> y <span
class="math inline"><em>b</em></span>. Para ello, tenemios que dar dos
pasos:</p>
<ol>
<li>Calcula <span
class="math inline"><em>ŷ</em> = <em>A</em> = <em>σ</em>(<em>W</em><sup><em>T</em></sup><em>X</em>+<em>b</em>)</span>.</li>
<li>Convierte la predicción a 0 (si <span
class="math inline"><em>ŷ</em> &lt; 0.5</span>) o a 1 (si <span
class="math inline"><em>ŷ</em> ≥ 0.5)</span>. Guarda todas las
predicciones en el array Y_prediction.</li>
</ol>
</div>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="5zMLVnPP0svc" data-outputId="73d9458c-6694-4a0c-9d2d-ca61c3703e1e">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> predict(w, b, X):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&#39;&#39;&#39;</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Dados los parametros de la regresion logistica (w, b), predice las clases (0 o 1) de las muestras.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Input:</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">    w -- pesos, numpy-array de tamaño (num_px * num_px * 3, 1).</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">    b -- parametro b (bias)).</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">    X -- Conjunto de muestras X de test. Dimension: (num_px * num_px * 3, number of examples)</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Output:</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Y_prediction -- numpy-array con todas las predicciones obtenidas para las muestras en X (0/1).</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">    &#39;&#39;&#39;</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    Y_prediction <span class="op">=</span> np.zeros((<span class="dv">1</span>,m))</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> w.reshape(X.shape[<span class="dv">0</span>], <span class="dv">1</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calcula el vector &quot;A&quot;, donde tendremos las probabilidades de que cada foto contenga un gato.</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">## PON TU CODIGO AQUI ##  (≈ 1 linea)</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> sigmoid(np.dot(w.T, X) <span class="op">+</span> b)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">######################</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(A.shape[<span class="dv">1</span>]):</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convierte las probabilidades A[0, i] a predicciones (0/1)</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>        <span class="co">## PON TU CODIGO AQUI ## (≈ 2 lineas)</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>        Y_prediction[<span class="dv">0</span>] <span class="op">=</span> np.where(A[<span class="dv">0</span>] <span class="op">&gt;=</span> <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>        <span class="co">######################</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span>(Y_prediction.shape <span class="op">==</span> (<span class="dv">1</span>, m))</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Y_prediction</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> np.array([[<span class="fl">0.1124579</span>],[<span class="fl">0.23106775</span>]])</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> <span class="op">-</span><span class="fl">0.3</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.array([[<span class="fl">1.</span>,<span class="op">-</span><span class="fl">1.1</span>,<span class="op">-</span><span class="fl">3.2</span>],[<span class="fl">1.2</span>,<span class="fl">2.</span>,<span class="fl">0.1</span>]])</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;predicciones = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(predict(w, b, X)))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>predicciones = [[1. 1. 0.]]
</code></pre>
</div>
</div>
<section id="construye-el-modelo-y-el-clasificador"
class="cell markdown" id="PmNW2nJ3151H">
<h1>Construye el modelo y el clasificador</h1>
<p>Ya tenemos todos los ingredientes. Ahora usaremos todas las funciones
anteriores para aplicar un clasificador de regresión logística a nuestro
dataset.</p>
<p><strong>Ejercicio:</strong> Implementa el modelo usando las funciones
anteriores. Utiliza los siguientes nombres para declarar las
variables:</p>
<ul>
<li>Y_prediction_test: predicciones hechas sobre el dataset de
test.</li>
<li>Y_prediction_train: predicciones hechas sobre el dataset de
train.</li>
</ul>
</section>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="N4V65F942pXA" data-outputId="214a593f-51fc-43b7-8e6e-afa9b1222387">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(X_train, Y_train, X_test, Y_test, num_iterations <span class="op">=</span> <span class="dv">2000</span>, learning_rate <span class="op">=</span> <span class="fl">0.5</span>, print_cost <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Implementa el modelo de regresion logisitca usando las funciones implementadas anteriormente.</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Input:</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co">    X_train -- numpy-array con el conjunto de muestras X de train. Dimension: (num_px * num_px * 3, m_train)</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Y_train -- numpy-array con el conjunto de etiquetas Y de train (0 -&gt; no gato, 1 -&gt; gato). Dimension: (1, m_train)</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">    X_test -- numpy-array con el conjunto de muestras X de test. Dimension: (num_px * num_px * 3, m_test)</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Y_test -- numpy-array con el conjunto de etiquetas Y de test (0 -&gt; no gato, 1 -&gt; gato). Dimension: (1, m_test)</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co">    num_iterations -- Numero de iteraciones del algoritmo de gradient descent.</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co">    learning_rate -- hyperparametro que representa la tasa de aprendizaje (learning rate) de la regla de actualizacion en la función optimize().</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co">    print_cost -- True para imprimir el coste cada 100 iteraciones.</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Output:</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co">    d -- diccionario con la informacion sobre el modelo (coste, predicciones de tes, predicciones de train, w, b, tasa de aprendizaje y numero de iteraciones).</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">## PON TU CODIGO AQUI ##</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Inicializa los parametros a 0 (≈ 1 linea)</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    w, b <span class="op">=</span> initialize_with_zeros(X_train.shape[<span class="dv">0</span>])</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Gradient descent (≈ 1 linea)</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>    parameters, grads, costs <span class="op">=</span> optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extrae los parametros w y b</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> parameters[<span class="st">&quot;w&quot;</span>]</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> parameters[<span class="st">&quot;b&quot;</span>]</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Predice las clases para las muestras de train y de test (≈ 2 lineas)</span></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    Y_prediction_test <span class="op">=</span> predict(w, b, X_test)</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>    Y_prediction_train <span class="op">=</span> predict(w, b, X_train)</span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#####################</span></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Imprime la metrica de accuracy tanto para train como para test.</span></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;train accuracy: </span><span class="sc">{}</span><span class="st"> %&quot;</span>.<span class="bu">format</span>(<span class="dv">100</span> <span class="op">-</span> np.mean(np.<span class="bu">abs</span>(Y_prediction_train <span class="op">-</span> Y_train)) <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;test accuracy: </span><span class="sc">{}</span><span class="st"> %&quot;</span>.<span class="bu">format</span>(<span class="dv">100</span> <span class="op">-</span> np.mean(np.<span class="bu">abs</span>(Y_prediction_test <span class="op">-</span> Y_test)) <span class="op">*</span> <span class="dv">100</span>))</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> {<span class="st">&quot;cost&quot;</span>: costs,</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;Y_prediction_test&quot;</span>: Y_prediction_test,</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;Y_prediction_train&quot;</span> : Y_prediction_train,</span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;w&quot;</span> : w,</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;b&quot;</span> : b,</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;lr&quot;</span> : learning_rate,</span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>         <span class="st">&quot;iterations&quot;</span>: num_iterations}</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> d</span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations <span class="op">=</span> <span class="dv">2000</span>, learning_rate <span class="op">=</span> <span class="fl">0.005</span>, print_cost <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Vamos a imprimir un ejemplo.</span></span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>index <span class="op">=</span> <span class="dv">21</span></span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>plt.figure(<span class="dv">1</span>)</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>plt.imshow(test_set_x[:,index].reshape((num_px, num_px, <span class="dv">3</span>)))</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span> (<span class="st">&quot;y = &quot;</span> <span class="op">+</span> <span class="bu">str</span>(test_set_y[<span class="dv">0</span>,index])<span class="op">+</span> <span class="st">&quot;, you predicted that it is a </span><span class="ch">\&quot;</span><span class="st">&quot;</span> <span class="op">+</span> classes[test_set_y[<span class="dv">0</span>,index]].decode(<span class="st">&quot;utf-8&quot;</span>) <span class="op">+</span>  <span class="st">&quot;</span><span class="ch">\&quot;</span><span class="st"> picture.&quot;</span>)</span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprime la grafica del coste (curva de aprendizaje)</span></span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>costs <span class="op">=</span> np.squeeze(d[<span class="st">&#39;cost&#39;</span>])</span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>plt.figure(<span class="dv">2</span>)</span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a>plt.plot(costs)</span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Coste&#39;</span>)</span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Iteraciones (en porcentajes)&#39;</span>)</span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Tasa de aprendizaje =&quot;</span> <span class="op">+</span> <span class="bu">str</span>(d[<span class="st">&quot;lr&quot;</span>]))</span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Cost after iteration 0: 0.693147
Cost after iteration 100: 0.584508
Cost after iteration 200: 0.466949
Cost after iteration 300: 0.376007
Cost after iteration 400: 0.331463
Cost after iteration 500: 0.303273
Cost after iteration 600: 0.279880
Cost after iteration 700: 0.260042
Cost after iteration 800: 0.242941
Cost after iteration 900: 0.228004
Cost after iteration 1000: 0.214820
Cost after iteration 1100: 0.203078
Cost after iteration 1200: 0.192544
Cost after iteration 1300: 0.183033
Cost after iteration 1400: 0.174399
Cost after iteration 1500: 0.166521
Cost after iteration 1600: 0.159305
Cost after iteration 1700: 0.152667
Cost after iteration 1800: 0.146542
Cost after iteration 1900: 0.140872
train accuracy: 99.04306220095694 %
test accuracy: 70.0 %
y = 0, you predicted that it is a &quot;non-cat&quot; picture.
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_80e758b3b43443038c279ae53cfe7ffc/964b851a74234bbf32e8122f77f8c3887e1bb7a7.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_80e758b3b43443038c279ae53cfe7ffc/b09e48ec8c82e200846d286d91a355e5bd70832d.png" /></p>
</div>
</div>
</body>
</html>
